{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes\n",
    "\n",
    "1. Title: Pima Indians Diabetes Database\n",
    "\n",
    "2. Sources:\n",
    "   (a) Original owners: National Institute of Diabetes and Digestive and\n",
    "                        Kidney Diseases\n",
    "   (b) Donor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu)\n",
    "                          Research Center, RMI Group Leader\n",
    "                          Applied Physics Laboratory\n",
    "                          The Johns Hopkins University\n",
    "                          Johns Hopkins Road\n",
    "                          Laurel, MD 20707\n",
    "                          (301) 953-6231\n",
    "   (c) Date received: 9 May 1990\n",
    "\n",
    "3. Past Usage:\n",
    "    1. Smith,~J.~W., Everhart,~J.~E., Dickson,~W.~C., Knowler,~W.~C., \\&\n",
    "       Johannes,~R.~S. (1988). Using the ADAP learning algorithm to forecast\n",
    "       the onset of diabetes mellitus.  In {\\it Proceedings of the Symposium\n",
    "       on Computer Applications and Medical Care} (pp. 261--265).  IEEE\n",
    "       Computer Society Press.\n",
    "\n",
    "       The diagnostic, binary-valued variable investigated is whether the\n",
    "       patient shows signs of diabetes according to World Health Organization\n",
    "       criteria (i.e., if the 2 hour post-load plasma glucose was at least \n",
    "       200 mg/dl at any survey  examination or if found during routine medical\n",
    "       care).   The population lives near Phoenix, Arizona, USA.\n",
    "\n",
    "       Results: Their ADAP algorithm makes a real-valued prediction between\n",
    "       0 and 1.  This was transformed into a binary decision using a cutoff of \n",
    "       0.448.  Using 576 training instances, the sensitivity and specificity\n",
    "       of their algorithm was 76% on the remaining 192 instances.\n",
    "\n",
    "4. Relevant Information:\n",
    "      Several constraints were placed on the selection of these instances from\n",
    "      a larger database.  In particular, all patients here are females at\n",
    "      least 21 years old of Pima Indian heritage.  ADAP is an adaptive learning\n",
    "      routine that generates and executes digital analogs of perceptron-like\n",
    "      devices.  It is a unique algorithm; see the paper for details.\n",
    "\n",
    "5. Number of Instances: 768\n",
    "\n",
    "6. Number of Attributes: 8 plus class \n",
    "\n",
    "    7. For Each Attribute: (all numeric-valued)\n",
    "       1. Number of times pregnant\n",
    "       2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "       3. Diastolic blood pressure (mm Hg)\n",
    "       4. Triceps skin fold thickness (mm)\n",
    "       5. 2-Hour serum insulin (mu U/ml)\n",
    "       6. Body mass index (weight in kg/(height in m)^2)\n",
    "       7. Diabetes pedigree function\n",
    "       8. Age (years)\n",
    "       9. Class variable (0 or 1)\n",
    "\n",
    "8. Missing Attribute Values: Yes\n",
    "\n",
    "9. Class Distribution: (class value 1 is interpreted as \"tested positive for\n",
    "   diabetes\")\n",
    "\n",
    "   Class Value  Number of instances\n",
    "   0            500\n",
    "   1            268\n",
    "\n",
    "10. Brief statistical analysis:\n",
    "\n",
    "        Attribute number:    Mean:   Standard Deviation:\n",
    "        1.                     3.8     3.4\n",
    "        2.                   120.9    32.0\n",
    "        3.                    69.1    19.4\n",
    "        4.                    20.5    16.0\n",
    "        5.                    79.8   115.2\n",
    "        6.                    32.0     7.9\n",
    "        7.                     0.5     0.3\n",
    "        8.                    33.2    11.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   6  148  72  35   0  33.6  0.627  50  1\n",
       "0  1   85  66  29   0  26.6  0.351  31  0\n",
       "1  8  183  64   0   0  23.3  0.672  32  1\n",
       "2  1   89  66  23  94  28.1  0.167  21  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./dataset/pima-indians-diabetes.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add names to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'number_pregnant', \n",
    "    'glucose_concentration', \n",
    "    'blood_pressure', \n",
    "    'triceps', \n",
    "    'insulin', \n",
    "    'bmi', \n",
    "    'pedigree', \n",
    "    'age', \n",
    "    'class'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_pregnant  glucose_concentration  blood_pressure  triceps  insulin  \\\n",
       "0                1                     85              66       29        0   \n",
       "1                8                    183              64        0        0   \n",
       "2                1                     89              66       23       94   \n",
       "3                0                    137              40       35      168   \n",
       "4                5                    116              74        0        0   \n",
       "\n",
       "    bmi  pedigree  age  class  \n",
       "0  26.6     0.351   31      0  \n",
       "1  23.3     0.672   32      1  \n",
       "2  28.1     0.167   21      0  \n",
       "3  43.1     2.288   33      1  \n",
       "4  25.6     0.201   30      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_data = data['class'].as_matrix().astype(np.int32)\n",
    "feat_data = data.drop('class', axis=1).as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.zeros((label_data.shape[0], len(set(label_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(labels.shape[0]):\n",
    "    labels[i, label_data[i]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feat_data,\n",
    "    labels,\n",
    "    test_size=0.3,\n",
    "    random_state=77\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_x_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_x_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 8\n",
    "n_hidden_1 = 13\n",
    "n_hidden_2 = 10\n",
    "n_hidden_3 = 13\n",
    "n_outputs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, n_outputs])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'W1': tf.Variable(tf.truncated_normal([n_inputs, n_hidden_1], stddev=0.001)),\n",
    "    'W2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2], stddev=0.001)),\n",
    "    'W3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3], stddev=0.001)),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_3, n_outputs], stddev=0.001))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_outputs]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_1 = tf.nn.sigmoid(tf.matmul(X, weights['W1']) + biases['b1'])\n",
    "layer_2 = tf.nn.sigmoid(tf.matmul(layer_1, weights['W2']) + biases['b2'])\n",
    "layer_3 = tf.nn.sigmoid(tf.matmul(layer_2, weights['W3']) + biases['b3'])\n",
    "y_pred = tf.matmul(layer_3, weights['out']) + biases['out']\n",
    "y_pred = tf.nn.dropout(y_pred, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = 5000\n",
    "dropout = 0.5\n",
    "batch_sz = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON STEM: 00001    ACCURACY: 0.44589    LOSS: 1.58876\n",
      "ON STEM: 00001    ACCURACY: 0.41558    LOSS: 1.56591\n",
      "ON STEM: 00001    ACCURACY: 0.41991    LOSS: 1.55874\n",
      "ON STEM: 00001    ACCURACY: 0.42424    LOSS: 1.46359\n",
      "ON STEM: 00001    ACCURACY: 0.41991    LOSS: 1.40928\n",
      "ON STEM: 00001    ACCURACY: 0.47186    LOSS: 1.30183\n",
      "ON STEM: 00101    ACCURACY: 0.73160    LOSS: 0.54029\n",
      "ON STEM: 00101    ACCURACY: 0.74026    LOSS: 0.51357\n",
      "ON STEM: 00101    ACCURACY: 0.74026    LOSS: 0.56610\n",
      "ON STEM: 00101    ACCURACY: 0.73593    LOSS: 0.55439\n",
      "ON STEM: 00101    ACCURACY: 0.75325    LOSS: 0.48963\n",
      "ON STEM: 00101    ACCURACY: 0.76190    LOSS: 0.53635\n",
      "ON STEM: 00201    ACCURACY: 0.74026    LOSS: 0.51887\n",
      "ON STEM: 00201    ACCURACY: 0.80087    LOSS: 0.51154\n",
      "ON STEM: 00201    ACCURACY: 0.75325    LOSS: 0.52264\n",
      "ON STEM: 00201    ACCURACY: 0.79221    LOSS: 0.52382\n",
      "ON STEM: 00201    ACCURACY: 0.79221    LOSS: 0.52770\n",
      "ON STEM: 00201    ACCURACY: 0.77056    LOSS: 0.53562\n",
      "ON STEM: 00301    ACCURACY: 0.74892    LOSS: 0.52453\n",
      "ON STEM: 00301    ACCURACY: 0.72727    LOSS: 0.51976\n",
      "ON STEM: 00301    ACCURACY: 0.78788    LOSS: 0.52273\n",
      "ON STEM: 00301    ACCURACY: 0.77489    LOSS: 0.51192\n",
      "ON STEM: 00301    ACCURACY: 0.74026    LOSS: 0.53665\n",
      "ON STEM: 00301    ACCURACY: 0.79654    LOSS: 0.52158\n",
      "ON STEM: 00401    ACCURACY: 0.74459    LOSS: 0.55514\n",
      "ON STEM: 00401    ACCURACY: 0.75325    LOSS: 0.52403\n",
      "ON STEM: 00401    ACCURACY: 0.75325    LOSS: 0.51188\n",
      "ON STEM: 00401    ACCURACY: 0.72294    LOSS: 0.50967\n",
      "ON STEM: 00401    ACCURACY: 0.74892    LOSS: 0.47939\n",
      "ON STEM: 00401    ACCURACY: 0.71861    LOSS: 0.51948\n",
      "ON STEM: 00501    ACCURACY: 0.76190    LOSS: 0.50375\n",
      "ON STEM: 00501    ACCURACY: 0.74892    LOSS: 0.51495\n",
      "ON STEM: 00501    ACCURACY: 0.75325    LOSS: 0.51218\n",
      "ON STEM: 00501    ACCURACY: 0.77056    LOSS: 0.52802\n",
      "ON STEM: 00501    ACCURACY: 0.77489    LOSS: 0.52525\n",
      "ON STEM: 00501    ACCURACY: 0.76190    LOSS: 0.50558\n",
      "ON STEM: 00601    ACCURACY: 0.77056    LOSS: 0.50138\n",
      "ON STEM: 00601    ACCURACY: 0.78355    LOSS: 0.54306\n",
      "ON STEM: 00601    ACCURACY: 0.75758    LOSS: 0.52948\n",
      "ON STEM: 00601    ACCURACY: 0.78355    LOSS: 0.50995\n",
      "ON STEM: 00601    ACCURACY: 0.75758    LOSS: 0.56811\n",
      "ON STEM: 00601    ACCURACY: 0.73593    LOSS: 0.56390\n",
      "ON STEM: 00701    ACCURACY: 0.76190    LOSS: 0.57511\n",
      "ON STEM: 00701    ACCURACY: 0.77489    LOSS: 0.51830\n",
      "ON STEM: 00701    ACCURACY: 0.73593    LOSS: 0.51121\n",
      "ON STEM: 00701    ACCURACY: 0.75758    LOSS: 0.51235\n",
      "ON STEM: 00701    ACCURACY: 0.76190    LOSS: 0.54102\n",
      "ON STEM: 00701    ACCURACY: 0.77056    LOSS: 0.55050\n",
      "ON STEM: 00801    ACCURACY: 0.75325    LOSS: 0.55463\n",
      "ON STEM: 00801    ACCURACY: 0.78788    LOSS: 0.53131\n",
      "ON STEM: 00801    ACCURACY: 0.77922    LOSS: 0.50787\n",
      "ON STEM: 00801    ACCURACY: 0.78355    LOSS: 0.50538\n",
      "ON STEM: 00801    ACCURACY: 0.77489    LOSS: 0.48930\n",
      "ON STEM: 00801    ACCURACY: 0.75325    LOSS: 0.55849\n",
      "ON STEM: 00901    ACCURACY: 0.75325    LOSS: 0.50768\n",
      "ON STEM: 00901    ACCURACY: 0.78788    LOSS: 0.52821\n",
      "ON STEM: 00901    ACCURACY: 0.74892    LOSS: 0.53499\n",
      "ON STEM: 00901    ACCURACY: 0.78355    LOSS: 0.44859\n",
      "ON STEM: 00901    ACCURACY: 0.73593    LOSS: 0.52606\n",
      "ON STEM: 00901    ACCURACY: 0.74892    LOSS: 0.57796\n",
      "ON STEM: 01001    ACCURACY: 0.72294    LOSS: 0.51857\n",
      "ON STEM: 01001    ACCURACY: 0.74892    LOSS: 0.54016\n",
      "ON STEM: 01001    ACCURACY: 0.73593    LOSS: 0.52439\n",
      "ON STEM: 01001    ACCURACY: 0.74459    LOSS: 0.54345\n",
      "ON STEM: 01001    ACCURACY: 0.76190    LOSS: 0.50270\n",
      "ON STEM: 01001    ACCURACY: 0.73593    LOSS: 0.54917\n",
      "ON STEM: 01101    ACCURACY: 0.78355    LOSS: 0.52740\n",
      "ON STEM: 01101    ACCURACY: 0.75325    LOSS: 0.54296\n",
      "ON STEM: 01101    ACCURACY: 0.74026    LOSS: 0.48972\n",
      "ON STEM: 01101    ACCURACY: 0.77489    LOSS: 0.53591\n",
      "ON STEM: 01101    ACCURACY: 0.77056    LOSS: 0.52276\n",
      "ON STEM: 01101    ACCURACY: 0.76190    LOSS: 0.51096\n",
      "ON STEM: 01201    ACCURACY: 0.74026    LOSS: 0.52361\n",
      "ON STEM: 01201    ACCURACY: 0.74892    LOSS: 0.48893\n",
      "ON STEM: 01201    ACCURACY: 0.75325    LOSS: 0.53085\n",
      "ON STEM: 01201    ACCURACY: 0.75325    LOSS: 0.48621\n",
      "ON STEM: 01201    ACCURACY: 0.74026    LOSS: 0.53449\n",
      "ON STEM: 01201    ACCURACY: 0.76623    LOSS: 0.51542\n",
      "ON STEM: 01301    ACCURACY: 0.76623    LOSS: 0.49045\n",
      "ON STEM: 01301    ACCURACY: 0.75758    LOSS: 0.54052\n",
      "ON STEM: 01301    ACCURACY: 0.76190    LOSS: 0.51646\n",
      "ON STEM: 01301    ACCURACY: 0.75758    LOSS: 0.47904\n",
      "ON STEM: 01301    ACCURACY: 0.76190    LOSS: 0.52047\n",
      "ON STEM: 01301    ACCURACY: 0.75325    LOSS: 0.55499\n",
      "ON STEM: 01401    ACCURACY: 0.75758    LOSS: 0.53676\n",
      "ON STEM: 01401    ACCURACY: 0.75758    LOSS: 0.53246\n",
      "ON STEM: 01401    ACCURACY: 0.77056    LOSS: 0.52411\n",
      "ON STEM: 01401    ACCURACY: 0.77056    LOSS: 0.51304\n",
      "ON STEM: 01401    ACCURACY: 0.74892    LOSS: 0.51781\n",
      "ON STEM: 01401    ACCURACY: 0.73160    LOSS: 0.52024\n",
      "ON STEM: 01501    ACCURACY: 0.75325    LOSS: 0.47284\n",
      "ON STEM: 01501    ACCURACY: 0.74892    LOSS: 0.50326\n",
      "ON STEM: 01501    ACCURACY: 0.70563    LOSS: 0.55405\n",
      "ON STEM: 01501    ACCURACY: 0.74892    LOSS: 0.51140\n",
      "ON STEM: 01501    ACCURACY: 0.75758    LOSS: 0.51166\n",
      "ON STEM: 01501    ACCURACY: 0.76623    LOSS: 0.53448\n",
      "ON STEM: 01601    ACCURACY: 0.74892    LOSS: 0.54353\n",
      "ON STEM: 01601    ACCURACY: 0.74459    LOSS: 0.52389\n",
      "ON STEM: 01601    ACCURACY: 0.75325    LOSS: 0.50940\n",
      "ON STEM: 01601    ACCURACY: 0.74459    LOSS: 0.48033\n",
      "ON STEM: 01601    ACCURACY: 0.78355    LOSS: 0.48889\n",
      "ON STEM: 01601    ACCURACY: 0.74459    LOSS: 0.49854\n",
      "ON STEM: 01701    ACCURACY: 0.76190    LOSS: 0.52499\n",
      "ON STEM: 01701    ACCURACY: 0.74892    LOSS: 0.52748\n",
      "ON STEM: 01701    ACCURACY: 0.77056    LOSS: 0.53284\n",
      "ON STEM: 01701    ACCURACY: 0.77489    LOSS: 0.49743\n",
      "ON STEM: 01701    ACCURACY: 0.77922    LOSS: 0.52979\n",
      "ON STEM: 01701    ACCURACY: 0.75325    LOSS: 0.56258\n",
      "ON STEM: 01801    ACCURACY: 0.75758    LOSS: 0.53117\n",
      "ON STEM: 01801    ACCURACY: 0.74892    LOSS: 0.52684\n",
      "ON STEM: 01801    ACCURACY: 0.75758    LOSS: 0.53301\n",
      "ON STEM: 01801    ACCURACY: 0.74892    LOSS: 0.54561\n",
      "ON STEM: 01801    ACCURACY: 0.75325    LOSS: 0.56448\n",
      "ON STEM: 01801    ACCURACY: 0.73160    LOSS: 0.56048\n",
      "ON STEM: 01901    ACCURACY: 0.74892    LOSS: 0.55871\n",
      "ON STEM: 01901    ACCURACY: 0.77056    LOSS: 0.52402\n",
      "ON STEM: 01901    ACCURACY: 0.77056    LOSS: 0.51270\n",
      "ON STEM: 01901    ACCURACY: 0.78355    LOSS: 0.52283\n",
      "ON STEM: 01901    ACCURACY: 0.77489    LOSS: 0.54355\n",
      "ON STEM: 01901    ACCURACY: 0.73593    LOSS: 0.55673\n",
      "ON STEM: 02001    ACCURACY: 0.75325    LOSS: 0.54200\n",
      "ON STEM: 02001    ACCURACY: 0.76190    LOSS: 0.59194\n",
      "ON STEM: 02001    ACCURACY: 0.75325    LOSS: 0.53244\n",
      "ON STEM: 02001    ACCURACY: 0.73593    LOSS: 0.55398\n",
      "ON STEM: 02001    ACCURACY: 0.77056    LOSS: 0.53555\n",
      "ON STEM: 02001    ACCURACY: 0.74892    LOSS: 0.54639\n",
      "ON STEM: 02101    ACCURACY: 0.74892    LOSS: 0.49851\n",
      "ON STEM: 02101    ACCURACY: 0.77922    LOSS: 0.56179\n",
      "ON STEM: 02101    ACCURACY: 0.76623    LOSS: 0.53200\n",
      "ON STEM: 02101    ACCURACY: 0.75758    LOSS: 0.58615\n",
      "ON STEM: 02101    ACCURACY: 0.75758    LOSS: 0.53610\n",
      "ON STEM: 02101    ACCURACY: 0.76190    LOSS: 0.51921\n",
      "ON STEM: 02201    ACCURACY: 0.74892    LOSS: 0.55771\n",
      "ON STEM: 02201    ACCURACY: 0.74892    LOSS: 0.53086\n",
      "ON STEM: 02201    ACCURACY: 0.76623    LOSS: 0.53469\n",
      "ON STEM: 02201    ACCURACY: 0.74459    LOSS: 0.57410\n",
      "ON STEM: 02201    ACCURACY: 0.74892    LOSS: 0.56442\n",
      "ON STEM: 02201    ACCURACY: 0.74459    LOSS: 0.55846\n",
      "ON STEM: 02301    ACCURACY: 0.74026    LOSS: 0.59394\n",
      "ON STEM: 02301    ACCURACY: 0.75325    LOSS: 0.54803\n",
      "ON STEM: 02301    ACCURACY: 0.72294    LOSS: 0.61401\n",
      "ON STEM: 02301    ACCURACY: 0.76190    LOSS: 0.51235\n",
      "ON STEM: 02301    ACCURACY: 0.75325    LOSS: 0.58961\n",
      "ON STEM: 02301    ACCURACY: 0.74892    LOSS: 0.54694\n",
      "ON STEM: 02401    ACCURACY: 0.73593    LOSS: 0.56144\n",
      "ON STEM: 02401    ACCURACY: 0.73160    LOSS: 0.60029\n",
      "ON STEM: 02401    ACCURACY: 0.76190    LOSS: 0.57927\n",
      "ON STEM: 02401    ACCURACY: 0.74892    LOSS: 0.58004\n",
      "ON STEM: 02401    ACCURACY: 0.77489    LOSS: 0.61290\n",
      "ON STEM: 02401    ACCURACY: 0.75758    LOSS: 0.56537\n",
      "ON STEM: 02501    ACCURACY: 0.76190    LOSS: 0.57604\n",
      "ON STEM: 02501    ACCURACY: 0.75758    LOSS: 0.55208\n",
      "ON STEM: 02501    ACCURACY: 0.74459    LOSS: 0.59186\n",
      "ON STEM: 02501    ACCURACY: 0.73160    LOSS: 0.56440\n",
      "ON STEM: 02501    ACCURACY: 0.70130    LOSS: 0.59467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON STEM: 02501    ACCURACY: 0.73160    LOSS: 0.59458\n",
      "ON STEM: 02601    ACCURACY: 0.71861    LOSS: 0.62285\n",
      "ON STEM: 02601    ACCURACY: 0.72727    LOSS: 0.62166\n",
      "ON STEM: 02601    ACCURACY: 0.72727    LOSS: 0.57455\n",
      "ON STEM: 02601    ACCURACY: 0.72727    LOSS: 0.51774\n",
      "ON STEM: 02601    ACCURACY: 0.75758    LOSS: 0.60041\n",
      "ON STEM: 02601    ACCURACY: 0.74459    LOSS: 0.55560\n",
      "ON STEM: 02701    ACCURACY: 0.76190    LOSS: 0.56990\n",
      "ON STEM: 02701    ACCURACY: 0.74459    LOSS: 0.60543\n",
      "ON STEM: 02701    ACCURACY: 0.76190    LOSS: 0.60848\n",
      "ON STEM: 02701    ACCURACY: 0.72727    LOSS: 0.64298\n",
      "ON STEM: 02701    ACCURACY: 0.77489    LOSS: 0.54837\n",
      "ON STEM: 02701    ACCURACY: 0.73160    LOSS: 0.56806\n",
      "ON STEM: 02801    ACCURACY: 0.71861    LOSS: 0.67129\n",
      "ON STEM: 02801    ACCURACY: 0.76623    LOSS: 0.54946\n",
      "ON STEM: 02801    ACCURACY: 0.74892    LOSS: 0.60204\n",
      "ON STEM: 02801    ACCURACY: 0.71861    LOSS: 0.66969\n",
      "ON STEM: 02801    ACCURACY: 0.75758    LOSS: 0.57343\n",
      "ON STEM: 02801    ACCURACY: 0.71861    LOSS: 0.59450\n",
      "ON STEM: 02901    ACCURACY: 0.77056    LOSS: 0.56611\n",
      "ON STEM: 02901    ACCURACY: 0.72294    LOSS: 0.53424\n",
      "ON STEM: 02901    ACCURACY: 0.72294    LOSS: 0.64009\n",
      "ON STEM: 02901    ACCURACY: 0.74459    LOSS: 0.51520\n",
      "ON STEM: 02901    ACCURACY: 0.75758    LOSS: 0.60585\n",
      "ON STEM: 02901    ACCURACY: 0.73593    LOSS: 0.61629\n",
      "ON STEM: 03001    ACCURACY: 0.74892    LOSS: 0.58638\n",
      "ON STEM: 03001    ACCURACY: 0.73593    LOSS: 0.55823\n",
      "ON STEM: 03001    ACCURACY: 0.71861    LOSS: 0.64757\n",
      "ON STEM: 03001    ACCURACY: 0.76190    LOSS: 0.57197\n",
      "ON STEM: 03001    ACCURACY: 0.73160    LOSS: 0.62592\n",
      "ON STEM: 03001    ACCURACY: 0.70563    LOSS: 0.62047\n",
      "ON STEM: 03101    ACCURACY: 0.72727    LOSS: 0.58470\n",
      "ON STEM: 03101    ACCURACY: 0.76190    LOSS: 0.64760\n",
      "ON STEM: 03101    ACCURACY: 0.74026    LOSS: 0.66991\n",
      "ON STEM: 03101    ACCURACY: 0.74026    LOSS: 0.60569\n",
      "ON STEM: 03101    ACCURACY: 0.74459    LOSS: 0.58020\n",
      "ON STEM: 03101    ACCURACY: 0.73160    LOSS: 0.58768\n",
      "ON STEM: 03201    ACCURACY: 0.74459    LOSS: 0.65299\n",
      "ON STEM: 03201    ACCURACY: 0.74026    LOSS: 0.64370\n",
      "ON STEM: 03201    ACCURACY: 0.72727    LOSS: 0.71543\n",
      "ON STEM: 03201    ACCURACY: 0.74026    LOSS: 0.69923\n",
      "ON STEM: 03201    ACCURACY: 0.74459    LOSS: 0.65400\n",
      "ON STEM: 03201    ACCURACY: 0.73160    LOSS: 0.73334\n",
      "ON STEM: 03301    ACCURACY: 0.75758    LOSS: 0.65480\n",
      "ON STEM: 03301    ACCURACY: 0.74459    LOSS: 0.59672\n",
      "ON STEM: 03301    ACCURACY: 0.73160    LOSS: 0.64237\n",
      "ON STEM: 03301    ACCURACY: 0.77056    LOSS: 0.61352\n",
      "ON STEM: 03301    ACCURACY: 0.77056    LOSS: 0.62429\n",
      "ON STEM: 03301    ACCURACY: 0.76190    LOSS: 0.65489\n",
      "ON STEM: 03401    ACCURACY: 0.74892    LOSS: 0.67025\n",
      "ON STEM: 03401    ACCURACY: 0.74459    LOSS: 0.63411\n",
      "ON STEM: 03401    ACCURACY: 0.72727    LOSS: 0.72159\n",
      "ON STEM: 03401    ACCURACY: 0.71861    LOSS: 0.64791\n",
      "ON STEM: 03401    ACCURACY: 0.74026    LOSS: 0.74841\n",
      "ON STEM: 03401    ACCURACY: 0.77056    LOSS: 0.69901\n",
      "ON STEM: 03501    ACCURACY: 0.76623    LOSS: 0.71798\n",
      "ON STEM: 03501    ACCURACY: 0.74026    LOSS: 0.75467\n",
      "ON STEM: 03501    ACCURACY: 0.74892    LOSS: 0.69030\n",
      "ON STEM: 03501    ACCURACY: 0.74892    LOSS: 0.68592\n",
      "ON STEM: 03501    ACCURACY: 0.74026    LOSS: 0.71319\n",
      "ON STEM: 03501    ACCURACY: 0.75758    LOSS: 0.70935\n",
      "ON STEM: 03601    ACCURACY: 0.76190    LOSS: 0.68901\n",
      "ON STEM: 03601    ACCURACY: 0.77922    LOSS: 0.69997\n",
      "ON STEM: 03601    ACCURACY: 0.74026    LOSS: 0.80774\n",
      "ON STEM: 03601    ACCURACY: 0.74026    LOSS: 0.64324\n",
      "ON STEM: 03601    ACCURACY: 0.74026    LOSS: 0.60305\n",
      "ON STEM: 03601    ACCURACY: 0.74892    LOSS: 0.61994\n",
      "ON STEM: 03701    ACCURACY: 0.72727    LOSS: 0.68342\n",
      "ON STEM: 03701    ACCURACY: 0.72294    LOSS: 0.87013\n",
      "ON STEM: 03701    ACCURACY: 0.74459    LOSS: 0.74738\n",
      "ON STEM: 03701    ACCURACY: 0.75325    LOSS: 0.73958\n",
      "ON STEM: 03701    ACCURACY: 0.73593    LOSS: 0.81537\n",
      "ON STEM: 03701    ACCURACY: 0.74892    LOSS: 0.71066\n",
      "ON STEM: 03801    ACCURACY: 0.71861    LOSS: 0.62573\n",
      "ON STEM: 03801    ACCURACY: 0.75758    LOSS: 0.60663\n",
      "ON STEM: 03801    ACCURACY: 0.75758    LOSS: 0.79695\n",
      "ON STEM: 03801    ACCURACY: 0.76623    LOSS: 0.77828\n",
      "ON STEM: 03801    ACCURACY: 0.73160    LOSS: 0.76506\n",
      "ON STEM: 03801    ACCURACY: 0.74892    LOSS: 0.69501\n",
      "ON STEM: 03901    ACCURACY: 0.72294    LOSS: 0.79938\n",
      "ON STEM: 03901    ACCURACY: 0.75325    LOSS: 0.59367\n",
      "ON STEM: 03901    ACCURACY: 0.74892    LOSS: 0.72503\n",
      "ON STEM: 03901    ACCURACY: 0.70563    LOSS: 0.75088\n",
      "ON STEM: 03901    ACCURACY: 0.75758    LOSS: 0.72065\n",
      "ON STEM: 03901    ACCURACY: 0.73160    LOSS: 0.85237\n",
      "ON STEM: 04001    ACCURACY: 0.71861    LOSS: 0.69703\n",
      "ON STEM: 04001    ACCURACY: 0.68831    LOSS: 0.87365\n",
      "ON STEM: 04001    ACCURACY: 0.70996    LOSS: 0.96168\n",
      "ON STEM: 04001    ACCURACY: 0.71429    LOSS: 0.73800\n",
      "ON STEM: 04001    ACCURACY: 0.70996    LOSS: 0.76402\n",
      "ON STEM: 04001    ACCURACY: 0.69697    LOSS: 0.79836\n",
      "ON STEM: 04101    ACCURACY: 0.77056    LOSS: 0.94877\n",
      "ON STEM: 04101    ACCURACY: 0.73593    LOSS: 0.77260\n",
      "ON STEM: 04101    ACCURACY: 0.75758    LOSS: 0.96771\n",
      "ON STEM: 04101    ACCURACY: 0.71861    LOSS: 0.77161\n",
      "ON STEM: 04101    ACCURACY: 0.71429    LOSS: 0.99279\n",
      "ON STEM: 04101    ACCURACY: 0.74026    LOSS: 0.83588\n",
      "ON STEM: 04201    ACCURACY: 0.70130    LOSS: 0.79576\n",
      "ON STEM: 04201    ACCURACY: 0.73593    LOSS: 0.72281\n",
      "ON STEM: 04201    ACCURACY: 0.73593    LOSS: 0.81452\n",
      "ON STEM: 04201    ACCURACY: 0.75325    LOSS: 0.74968\n",
      "ON STEM: 04201    ACCURACY: 0.73160    LOSS: 0.64911\n",
      "ON STEM: 04201    ACCURACY: 0.73593    LOSS: 0.81008\n",
      "ON STEM: 04301    ACCURACY: 0.70130    LOSS: 1.02665\n",
      "ON STEM: 04301    ACCURACY: 0.69264    LOSS: 0.91993\n",
      "ON STEM: 04301    ACCURACY: 0.70130    LOSS: 0.86672\n",
      "ON STEM: 04301    ACCURACY: 0.72294    LOSS: 0.82415\n",
      "ON STEM: 04301    ACCURACY: 0.70996    LOSS: 0.57916\n",
      "ON STEM: 04301    ACCURACY: 0.73160    LOSS: 0.79258\n",
      "ON STEM: 04401    ACCURACY: 0.70996    LOSS: 0.84655\n",
      "ON STEM: 04401    ACCURACY: 0.73160    LOSS: 0.71447\n",
      "ON STEM: 04401    ACCURACY: 0.70130    LOSS: 0.84321\n",
      "ON STEM: 04401    ACCURACY: 0.69264    LOSS: 0.85950\n",
      "ON STEM: 04401    ACCURACY: 0.73160    LOSS: 0.66251\n",
      "ON STEM: 04401    ACCURACY: 0.72727    LOSS: 0.72431\n",
      "ON STEM: 04501    ACCURACY: 0.68831    LOSS: 0.97996\n",
      "ON STEM: 04501    ACCURACY: 0.73160    LOSS: 0.69530\n",
      "ON STEM: 04501    ACCURACY: 0.68831    LOSS: 0.88811\n",
      "ON STEM: 04501    ACCURACY: 0.70996    LOSS: 0.81698\n",
      "ON STEM: 04501    ACCURACY: 0.71861    LOSS: 0.91652\n",
      "ON STEM: 04501    ACCURACY: 0.73160    LOSS: 0.86703\n",
      "ON STEM: 04601    ACCURACY: 0.66234    LOSS: 0.93444\n",
      "ON STEM: 04601    ACCURACY: 0.69264    LOSS: 0.84409\n",
      "ON STEM: 04601    ACCURACY: 0.71429    LOSS: 0.84267\n",
      "ON STEM: 04601    ACCURACY: 0.69697    LOSS: 0.89700\n",
      "ON STEM: 04601    ACCURACY: 0.68398    LOSS: 0.92649\n",
      "ON STEM: 04601    ACCURACY: 0.71429    LOSS: 0.96819\n",
      "ON STEM: 04701    ACCURACY: 0.72727    LOSS: 1.03265\n",
      "ON STEM: 04701    ACCURACY: 0.74892    LOSS: 0.80586\n",
      "ON STEM: 04701    ACCURACY: 0.77056    LOSS: 0.90238\n",
      "ON STEM: 04701    ACCURACY: 0.73593    LOSS: 1.02786\n",
      "ON STEM: 04701    ACCURACY: 0.74026    LOSS: 0.79378\n",
      "ON STEM: 04701    ACCURACY: 0.70996    LOSS: 0.87430\n",
      "ON STEM: 04801    ACCURACY: 0.70563    LOSS: 0.87557\n",
      "ON STEM: 04801    ACCURACY: 0.71861    LOSS: 0.93615\n",
      "ON STEM: 04801    ACCURACY: 0.72294    LOSS: 0.96275\n",
      "ON STEM: 04801    ACCURACY: 0.70996    LOSS: 0.81708\n",
      "ON STEM: 04801    ACCURACY: 0.74459    LOSS: 0.98041\n",
      "ON STEM: 04801    ACCURACY: 0.72727    LOSS: 0.98655\n",
      "ON STEM: 04901    ACCURACY: 0.70130    LOSS: 0.85651\n",
      "ON STEM: 04901    ACCURACY: 0.68398    LOSS: 1.00377\n",
      "ON STEM: 04901    ACCURACY: 0.68831    LOSS: 1.29569\n",
      "ON STEM: 04901    ACCURACY: 0.70130    LOSS: 1.04284\n",
      "ON STEM: 04901    ACCURACY: 0.67100    LOSS: 1.02802\n",
      "ON STEM: 04901    ACCURACY: 0.69264    LOSS: 1.11713\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    n_batches = scaled_x_train.shape[0] // batch_sz\n",
    "    for step in range(steps):\n",
    "        \n",
    "        for batch in range(n_batches):\n",
    "            shuffled_x_train, shuffled_y_train = shuffle(scaled_x_train, y_train)\n",
    "            \n",
    "            x_train_batch = shuffled_x_train[batch*batch_sz:(batch*batch_sz+batch_sz), :]\n",
    "            y_train_batch = shuffled_y_train[batch*batch_sz:(batch*batch_sz+batch_sz), :]\n",
    "            \n",
    "            sess.run(train, feed_dict={X: x_train_batch, y_true: y_train_batch, keep_prob:dropout})\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                matches = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "                accuracy = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "                acc, lss, preds = sess.run([accuracy, loss, y_pred], feed_dict={X: scaled_x_test, y_true: y_test, keep_prob:dropout})\n",
    "                print('ON STEM: {:05d}    ACCURACY: {:.5f}    LOSS: {:.5f}'.format(step+1, acc, lss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = np.argmax(preds, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.85      0.79       157\n",
      "          1       0.53      0.35      0.42        74\n",
      "\n",
      "avg / total       0.67      0.69      0.67       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
